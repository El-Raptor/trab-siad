{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "## Celso Antonio Uliana Junior\n",
    "## July 2 2020\n",
    "####\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#####\n",
    "## Consuming and shaping the data to analysis\n",
    "## Covid-19 numbers in Brazil by date\n",
    "## Isolation percentage in Brazil by date\n",
    "#####\n",
    "\n",
    "data_raw_covid = pd.read_csv(\"C:/Users/PCDOMILHAO/Documents/GitHub/trab-siad/scripts/Jupyter-Notebook/dados/covidBrasil.csv\", sep = \";\", decimal = \",\")\n",
    "data_raw_isolation = pd.read_csv(\"C:/Users/PCDOMILHAO/Documents/GitHub/trab-siad/scripts/Jupyter-Notebook/dados/isolamento.csv\", sep = \";\", decimal = \",\")\n",
    "data_covid = data_raw_covid['Data'].values.copy()\n",
    "data_covid = data_raw_covid.dropna().set_index(\"Data\")\n",
    "data_isolation = data_raw_isolation['Data'].values.copy()\n",
    "data_isolation = data_raw_isolation.dropna().set_index(\"Data\")\n",
    "\n",
    "####\n",
    "## Shaping a central pandas dataFrame for all our ML needs\n",
    "####\n",
    "\n",
    "data = data_covid\n",
    "data['Taxa'] = data_isolation['Taxa'].values.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casos</th>\n",
       "      <th>Taxa</th>\n",
       "      <th>CasosNormalizados</th>\n",
       "      <th>TaxaNormalizadas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26/2/20</th>\n",
       "      <td>1</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27/2/20</th>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/2/20</th>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/2/20</th>\n",
       "      <td>0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/3/20</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.461333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/6/20</th>\n",
       "      <td>34918</td>\n",
       "      <td>37.3</td>\n",
       "      <td>0.637527</td>\n",
       "      <td>0.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18/6/20</th>\n",
       "      <td>32188</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.587683</td>\n",
       "      <td>0.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19/6/20</th>\n",
       "      <td>22765</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.415640</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20/6/20</th>\n",
       "      <td>54771</td>\n",
       "      <td>39.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21/6/20</th>\n",
       "      <td>34666</td>\n",
       "      <td>47.3</td>\n",
       "      <td>0.632926</td>\n",
       "      <td>0.602667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Casos  Taxa  CasosNormalizados  TaxaNormalizadas\n",
       "Data                                                     \n",
       "26/2/20      1  24.7           0.000018          0.000000\n",
       "27/2/20      0  27.5           0.000000          0.074667\n",
       "28/2/20      0  26.6           0.000000          0.050667\n",
       "29/2/20      0  31.4           0.000000          0.178667\n",
       "1/3/20       1    42           0.000018          0.461333\n",
       "...        ...   ...                ...               ...\n",
       "17/6/20  34918  37.3           0.637527          0.336000\n",
       "18/6/20  32188  38.5           0.587683          0.368000\n",
       "19/6/20  22765  34.7           0.415640          0.266667\n",
       "20/6/20  54771  39.1           1.000000          0.384000\n",
       "21/6/20  34666  47.3           0.632926          0.602667\n",
       "\n",
       "[117 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "####\n",
    "## normalizing values for both covid and isolation percentage \n",
    "## between range [0,1] using sklearn MinMaxScaler\n",
    "####\n",
    "\n",
    "covid_norm = data_covid[\"Casos\"].values.copy()\n",
    "covid_norm.shape = (len(covid_norm), 1)\n",
    "\n",
    "isolation_norm = data_isolation[\"Taxa\"].values.copy()\n",
    "isolation_norm.shape = (len(isolation_norm), 1)\n",
    "\n",
    "####\n",
    "## Shaping the central dataFrame with normalized values\n",
    "####\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "covid_norm = min_max_scaler.fit_transform(covid_norm)\n",
    "isolation_norm = min_max_scaler.fit_transform(isolation_norm)\n",
    "\n",
    "data[\"CasosNormalizados\"] = covid_norm\n",
    "data[\"TaxaNormalizadas\"] = isolation_norm\n",
    "data.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               E0        E1        E2        E3        E4        E5        E6  \\\n",
      "Data                                                                            \n",
      "26/2/20  0.000018  0.000000  0.000000  0.000000  0.000018  0.000000  0.000000   \n",
      "27/2/20  0.000000  0.000000  0.000000  0.000018  0.000000  0.000000  0.000000   \n",
      "28/2/20  0.000000  0.000000  0.000018  0.000000  0.000000  0.000000  0.000018   \n",
      "29/2/20  0.000000  0.000018  0.000000  0.000000  0.000000  0.000018  0.000091   \n",
      "1/3/20   0.000018  0.000000  0.000000  0.000000  0.000018  0.000091  0.000091   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "11/6/20  0.600920  0.555257  0.474375  0.396268  0.312392  0.376970  0.637527   \n",
      "12/6/20  0.555257  0.474375  0.396268  0.312392  0.376970  0.637527  0.587683   \n",
      "13/6/20  0.474375  0.396268  0.312392  0.376970  0.637527  0.587683  0.415640   \n",
      "14/6/20  0.396268  0.312392  0.376970  0.637527  0.587683  0.415640  1.000000   \n",
      "15/6/20  0.312392  0.376970  0.637527  0.587683  0.415640  1.000000  0.632926   \n",
      "\n",
      "               E7        E8        E9       E10       E11       E12       E13  \\\n",
      "Data                                                                            \n",
      "26/2/20  0.000000  0.074667  0.050667  0.178667  0.461333  0.080000  0.114667   \n",
      "27/2/20  0.074667  0.050667  0.178667  0.461333  0.080000  0.114667  0.146667   \n",
      "28/2/20  0.050667  0.178667  0.461333  0.080000  0.114667  0.146667  0.133333   \n",
      "29/2/20  0.178667  0.461333  0.080000  0.114667  0.146667  0.133333  0.101333   \n",
      "1/3/20   0.461333  0.080000  0.114667  0.146667  0.133333  0.101333  0.189333   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "11/6/20  0.506667  0.322667  0.410667  0.645333  0.381333  0.384000  0.336000   \n",
      "12/6/20  0.322667  0.410667  0.645333  0.381333  0.384000  0.336000  0.368000   \n",
      "13/6/20  0.410667  0.645333  0.381333  0.384000  0.336000  0.368000  0.266667   \n",
      "14/6/20  0.645333  0.381333  0.384000  0.336000  0.368000  0.266667  0.384000   \n",
      "15/6/20  0.381333  0.384000  0.336000  0.368000  0.266667  0.384000  0.602667   \n",
      "\n",
      "              E14  \n",
      "Data               \n",
      "26/2/20  0.000000  \n",
      "27/2/20  0.000000  \n",
      "28/2/20  0.000018  \n",
      "29/2/20  0.000091  \n",
      "1/3/20   0.000091  \n",
      "...           ...  \n",
      "11/6/20  0.637527  \n",
      "12/6/20  0.587683  \n",
      "13/6/20  0.415640  \n",
      "14/6/20  1.000000  \n",
      "15/6/20  0.632926  \n",
      "\n",
      "[111 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "## Sliding window\n",
    "## This sliding window as show in timeSeriesForecasting is using future data as training and testing\n",
    "## the sliding window is actually inverse.\n",
    "####\n",
    "df = pd.DataFrame()\n",
    "window_size = 6\n",
    "for i in range(0, window_size + 1):\n",
    "    df['E{}'.format(i)] = data['CasosNormalizados'].shift(-i)\n",
    "    if(i == window_size):\n",
    "        for j in range(0, window_size + 1):\n",
    "             df['E{}'.format(j + i + 1)] = data['TaxaNormalizadas'].shift(-j)\n",
    "        df['E{}'.format(window_size * 2 + 2)] = data['CasosNormalizados'].shift(-window_size)\n",
    "df = df.iloc[: -window_size]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "## Manipulating the data to split into X(a window size of values)\n",
    "## and target, or Y, the value X \"produces\"\n",
    "####\n",
    "\n",
    "arr = df.values\n",
    "\n",
    "X = arr[:, : -1]\n",
    "target = arr[:, -1]\n",
    "#print(X)\n",
    "#print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.01693263\n",
      "Iteration 2, loss = 0.00912534\n",
      "Iteration 3, loss = 0.00439892\n",
      "Iteration 4, loss = 0.00850785\n",
      "Iteration 5, loss = 0.00536730\n",
      "Iteration 6, loss = 0.00566027\n",
      "Iteration 7, loss = 0.00458506\n",
      "Iteration 8, loss = 0.00245914\n",
      "Iteration 9, loss = 0.00277944\n",
      "Iteration 10, loss = 0.00337228\n",
      "Iteration 11, loss = 0.00265622\n",
      "Iteration 12, loss = 0.00261995\n",
      "Iteration 13, loss = 0.00314862\n",
      "Iteration 14, loss = 0.00252921\n",
      "Iteration 15, loss = 0.00195487\n",
      "Iteration 16, loss = 0.00222865\n",
      "Iteration 17, loss = 0.00210209\n",
      "Iteration 18, loss = 0.00171048\n",
      "Iteration 19, loss = 0.00203914\n",
      "Iteration 20, loss = 0.00197698\n",
      "Iteration 21, loss = 0.00160779\n",
      "Iteration 22, loss = 0.00162800\n",
      "Iteration 23, loss = 0.00159579\n",
      "Iteration 24, loss = 0.00133304\n",
      "Iteration 25, loss = 0.00131867\n",
      "Iteration 26, loss = 0.00142707\n",
      "Iteration 27, loss = 0.00129996\n",
      "Iteration 28, loss = 0.00118085\n",
      "Iteration 29, loss = 0.00121504\n",
      "Iteration 30, loss = 0.00113676\n",
      "Iteration 31, loss = 0.00099525\n",
      "Iteration 32, loss = 0.00100560\n",
      "Iteration 33, loss = 0.00102062\n",
      "Iteration 34, loss = 0.00093648\n",
      "Iteration 35, loss = 0.00091677\n",
      "Iteration 36, loss = 0.00092016\n",
      "Iteration 37, loss = 0.00082687\n",
      "Iteration 38, loss = 0.00078853\n",
      "Iteration 39, loss = 0.00080835\n",
      "Iteration 40, loss = 0.00075291\n",
      "Iteration 41, loss = 0.00072427\n",
      "Iteration 42, loss = 0.00072661\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.01779111\n",
      "Iteration 2, loss = 0.00911150\n",
      "Iteration 3, loss = 0.00549495\n",
      "Iteration 4, loss = 0.00799214\n",
      "Iteration 5, loss = 0.00562499\n",
      "Iteration 6, loss = 0.00570695\n",
      "Iteration 7, loss = 0.00379568\n",
      "Iteration 8, loss = 0.00236956\n",
      "Iteration 9, loss = 0.00290761\n",
      "Iteration 10, loss = 0.00266128\n",
      "Iteration 11, loss = 0.00246496\n",
      "Iteration 12, loss = 0.00290238\n",
      "Iteration 13, loss = 0.00232129\n",
      "Iteration 14, loss = 0.00190809\n",
      "Iteration 15, loss = 0.00205714\n",
      "Iteration 16, loss = 0.00176006\n",
      "Iteration 17, loss = 0.00169238\n",
      "Iteration 18, loss = 0.00191323\n",
      "Iteration 19, loss = 0.00168852\n",
      "Iteration 20, loss = 0.00155451\n",
      "Iteration 21, loss = 0.00156037\n",
      "Iteration 22, loss = 0.00135722\n",
      "Iteration 23, loss = 0.00124041\n",
      "Iteration 24, loss = 0.00132262\n",
      "Iteration 25, loss = 0.00126747\n",
      "Iteration 26, loss = 0.00117598\n",
      "Iteration 27, loss = 0.00119711\n",
      "Iteration 28, loss = 0.00112013\n",
      "Iteration 29, loss = 0.00098404\n",
      "Iteration 30, loss = 0.00097219\n",
      "Iteration 31, loss = 0.00096384\n",
      "Iteration 32, loss = 0.00089956\n",
      "Iteration 33, loss = 0.00090186\n",
      "Iteration 34, loss = 0.00088498\n",
      "Iteration 35, loss = 0.00080064\n",
      "Iteration 36, loss = 0.00077412\n",
      "Iteration 37, loss = 0.00075987\n",
      "Iteration 38, loss = 0.00071158\n",
      "Iteration 39, loss = 0.00071212\n",
      "Iteration 40, loss = 0.00070198\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.01824212\n",
      "Iteration 2, loss = 0.00829552\n",
      "Iteration 3, loss = 0.00560315\n",
      "Iteration 4, loss = 0.00663262\n",
      "Iteration 5, loss = 0.00614881\n",
      "Iteration 6, loss = 0.00540301\n",
      "Iteration 7, loss = 0.00321002\n",
      "Iteration 8, loss = 0.00268666\n",
      "Iteration 9, loss = 0.00228856\n",
      "Iteration 10, loss = 0.00222491\n",
      "Iteration 11, loss = 0.00280202\n",
      "Iteration 12, loss = 0.00257700\n",
      "Iteration 13, loss = 0.00226090\n",
      "Iteration 14, loss = 0.00215347\n",
      "Iteration 15, loss = 0.00179413\n",
      "Iteration 16, loss = 0.00175074\n",
      "Iteration 17, loss = 0.00182337\n",
      "Iteration 18, loss = 0.00165342\n",
      "Iteration 19, loss = 0.00166832\n",
      "Iteration 20, loss = 0.00154262\n",
      "Iteration 21, loss = 0.00136036\n",
      "Iteration 22, loss = 0.00134164\n",
      "Iteration 23, loss = 0.00122656\n",
      "Iteration 24, loss = 0.00118295\n",
      "Iteration 25, loss = 0.00120173\n",
      "Iteration 26, loss = 0.00111100\n",
      "Iteration 27, loss = 0.00108776\n",
      "Iteration 28, loss = 0.00103366\n",
      "Iteration 29, loss = 0.00094066\n",
      "Iteration 30, loss = 0.00092963\n",
      "Iteration 31, loss = 0.00087712\n",
      "Iteration 32, loss = 0.00085487\n",
      "Iteration 33, loss = 0.00085128\n",
      "Iteration 34, loss = 0.00079512\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.01860647\n",
      "Iteration 2, loss = 0.00978953\n",
      "Iteration 3, loss = 0.00591125\n",
      "Iteration 4, loss = 0.00808387\n",
      "Iteration 5, loss = 0.00592457\n",
      "Iteration 6, loss = 0.00610978\n",
      "Iteration 7, loss = 0.00396492\n",
      "Iteration 8, loss = 0.00249090\n",
      "Iteration 9, loss = 0.00294881\n",
      "Iteration 10, loss = 0.00260246\n",
      "Iteration 11, loss = 0.00241828\n",
      "Iteration 12, loss = 0.00301618\n",
      "Iteration 13, loss = 0.00265625\n",
      "Iteration 14, loss = 0.00204980\n",
      "Iteration 15, loss = 0.00214372\n",
      "Iteration 16, loss = 0.00202015\n",
      "Iteration 17, loss = 0.00170685\n",
      "Iteration 18, loss = 0.00191558\n",
      "Iteration 19, loss = 0.00194966\n",
      "Iteration 20, loss = 0.00167426\n",
      "Iteration 21, loss = 0.00164041\n",
      "Iteration 22, loss = 0.00157962\n",
      "Iteration 23, loss = 0.00131777\n",
      "Iteration 24, loss = 0.00128464\n",
      "Iteration 25, loss = 0.00135334\n",
      "Iteration 26, loss = 0.00125000\n",
      "Iteration 27, loss = 0.00119910\n",
      "Iteration 28, loss = 0.00122156\n",
      "Iteration 29, loss = 0.00110351\n",
      "Iteration 30, loss = 0.00098398\n",
      "Iteration 31, loss = 0.00098232\n",
      "Iteration 32, loss = 0.00093764\n",
      "Iteration 33, loss = 0.00087741\n",
      "Iteration 34, loss = 0.00090102\n",
      "Iteration 35, loss = 0.00087537\n",
      "Iteration 36, loss = 0.00079961\n",
      "Iteration 37, loss = 0.00077939\n",
      "Iteration 38, loss = 0.00074729\n",
      "Iteration 39, loss = 0.00069300\n",
      "Iteration 40, loss = 0.00069330\n",
      "Iteration 41, loss = 0.00068642\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.01878987\n",
      "Iteration 2, loss = 0.01007110\n",
      "Iteration 3, loss = 0.00573880\n",
      "Iteration 4, loss = 0.00860553\n",
      "Iteration 5, loss = 0.00599781\n",
      "Iteration 6, loss = 0.00613601\n",
      "Iteration 7, loss = 0.00427991\n",
      "Iteration 8, loss = 0.00241954\n",
      "Iteration 9, loss = 0.00287902\n",
      "Iteration 10, loss = 0.00289993\n",
      "Iteration 11, loss = 0.00240922\n",
      "Iteration 12, loss = 0.00291795\n",
      "Iteration 13, loss = 0.00290878\n",
      "Iteration 14, loss = 0.00212304\n",
      "Iteration 15, loss = 0.00203734\n",
      "Iteration 16, loss = 0.00216105\n",
      "Iteration 17, loss = 0.00181843\n",
      "Iteration 18, loss = 0.00181024\n",
      "Iteration 19, loss = 0.00205258\n",
      "Iteration 20, loss = 0.00182646\n",
      "Iteration 21, loss = 0.00159716\n",
      "Iteration 22, loss = 0.00161026\n",
      "Iteration 23, loss = 0.00144664\n",
      "Iteration 24, loss = 0.00124021\n",
      "Iteration 25, loss = 0.00130458\n",
      "Iteration 26, loss = 0.00134434\n",
      "Iteration 27, loss = 0.00120974\n",
      "Iteration 28, loss = 0.00117309\n",
      "Iteration 29, loss = 0.00116924\n",
      "Iteration 30, loss = 0.00102464\n",
      "Iteration 31, loss = 0.00093133\n",
      "Iteration 32, loss = 0.00096758\n",
      "Iteration 33, loss = 0.00093551\n",
      "Iteration 34, loss = 0.00087365\n",
      "Iteration 35, loss = 0.00089049\n",
      "Iteration 36, loss = 0.00085460\n",
      "Iteration 37, loss = 0.00076571\n",
      "Iteration 38, loss = 0.00075434\n",
      "Iteration 39, loss = 0.00074589\n",
      "Iteration 40, loss = 0.00069847\n",
      "Iteration 41, loss = 0.00069705\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.02011367\n",
      "Iteration 2, loss = 0.01024446\n",
      "Iteration 3, loss = 0.00544715\n",
      "Iteration 4, loss = 0.00919256\n",
      "Iteration 5, loss = 0.00649103\n",
      "Iteration 6, loss = 0.00610801\n",
      "Iteration 7, loss = 0.00466091\n",
      "Iteration 8, loss = 0.00246336\n",
      "Iteration 9, loss = 0.00264343\n",
      "Iteration 10, loss = 0.00309833\n",
      "Iteration 11, loss = 0.00257706\n",
      "Iteration 12, loss = 0.00280157\n",
      "Iteration 13, loss = 0.00303054\n",
      "Iteration 14, loss = 0.00227300\n",
      "Iteration 15, loss = 0.00192293\n",
      "Iteration 16, loss = 0.00212600\n",
      "Iteration 17, loss = 0.00192606\n",
      "Iteration 18, loss = 0.00175671\n",
      "Iteration 19, loss = 0.00202220\n",
      "Iteration 20, loss = 0.00196429\n",
      "Iteration 21, loss = 0.00164391\n",
      "Iteration 22, loss = 0.00157644\n",
      "Iteration 23, loss = 0.00151717\n",
      "Iteration 24, loss = 0.00129256\n",
      "Iteration 25, loss = 0.00124801\n",
      "Iteration 26, loss = 0.00136524\n",
      "Iteration 27, loss = 0.00130261\n",
      "Iteration 28, loss = 0.00118791\n",
      "Iteration 29, loss = 0.00118039\n",
      "Iteration 30, loss = 0.00110806\n",
      "Iteration 31, loss = 0.00096520\n",
      "Iteration 32, loss = 0.00095145\n",
      "Iteration 33, loss = 0.00098610\n",
      "Iteration 34, loss = 0.00092980\n",
      "Iteration 35, loss = 0.00089635\n",
      "Iteration 36, loss = 0.00090081\n",
      "Iteration 37, loss = 0.00082920\n",
      "Iteration 38, loss = 0.00076127\n",
      "Iteration 39, loss = 0.00076722\n",
      "Iteration 40, loss = 0.00074696\n",
      "Iteration 41, loss = 0.00071196\n",
      "Iteration 42, loss = 0.00071605\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.02060581\n",
      "Iteration 2, loss = 0.01026547\n",
      "Iteration 3, loss = 0.00547089\n",
      "Iteration 4, loss = 0.00954539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.00701508\n",
      "Iteration 6, loss = 0.00579151\n",
      "Iteration 7, loss = 0.00484399\n",
      "Iteration 8, loss = 0.00266403\n",
      "Iteration 9, loss = 0.00237429\n",
      "Iteration 10, loss = 0.00321241\n",
      "Iteration 11, loss = 0.00288163\n",
      "Iteration 12, loss = 0.00263938\n",
      "Iteration 13, loss = 0.00298433\n",
      "Iteration 14, loss = 0.00250150\n",
      "Iteration 15, loss = 0.00184916\n",
      "Iteration 16, loss = 0.00199732\n",
      "Iteration 17, loss = 0.00205921\n",
      "Iteration 18, loss = 0.00177616\n",
      "Iteration 19, loss = 0.00188777\n",
      "Iteration 20, loss = 0.00200526\n",
      "Iteration 21, loss = 0.00168852\n",
      "Iteration 22, loss = 0.00145997\n",
      "Iteration 23, loss = 0.00148445\n",
      "Iteration 24, loss = 0.00136284\n",
      "Iteration 25, loss = 0.00122852\n",
      "Iteration 26, loss = 0.00132062\n",
      "Iteration 27, loss = 0.00134723\n",
      "Iteration 28, loss = 0.00119532\n",
      "Iteration 29, loss = 0.00112484\n",
      "Iteration 30, loss = 0.00110775\n",
      "Iteration 31, loss = 0.00098949\n",
      "Iteration 32, loss = 0.00091846\n",
      "Iteration 33, loss = 0.00096757\n",
      "Iteration 34, loss = 0.00095768\n",
      "Iteration 35, loss = 0.00088950\n",
      "Iteration 36, loss = 0.00087732\n",
      "Iteration 37, loss = 0.00084658\n",
      "Iteration 38, loss = 0.00076956\n",
      "Iteration 39, loss = 0.00075597\n",
      "Iteration 40, loss = 0.00076923\n",
      "Iteration 41, loss = 0.00073557\n",
      "Iteration 42, loss = 0.00071320\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.02031031\n",
      "Iteration 2, loss = 0.01046748\n",
      "Iteration 3, loss = 0.00567397\n",
      "Iteration 4, loss = 0.00912743\n",
      "Iteration 5, loss = 0.00756164\n",
      "Iteration 6, loss = 0.00517580\n",
      "Iteration 7, loss = 0.00483164\n",
      "Iteration 8, loss = 0.00332427\n",
      "Iteration 9, loss = 0.00224735\n",
      "Iteration 10, loss = 0.00299720\n",
      "Iteration 11, loss = 0.00329831\n",
      "Iteration 12, loss = 0.00265779\n",
      "Iteration 13, loss = 0.00260275\n",
      "Iteration 14, loss = 0.00276166\n",
      "Iteration 15, loss = 0.00216288\n",
      "Iteration 16, loss = 0.00176438\n",
      "Iteration 17, loss = 0.00206489\n",
      "Iteration 18, loss = 0.00209241\n",
      "Iteration 19, loss = 0.00178118\n",
      "Iteration 20, loss = 0.00182953\n",
      "Iteration 21, loss = 0.00188823\n",
      "Iteration 22, loss = 0.00154933\n",
      "Iteration 23, loss = 0.00129706\n",
      "Iteration 24, loss = 0.00136097\n",
      "Iteration 25, loss = 0.00134194\n",
      "Iteration 26, loss = 0.00121220\n",
      "Iteration 27, loss = 0.00123841\n",
      "Iteration 28, loss = 0.00126020\n",
      "Iteration 29, loss = 0.00109517\n",
      "Iteration 30, loss = 0.00096469\n",
      "Iteration 31, loss = 0.00097470\n",
      "Iteration 32, loss = 0.00092978\n",
      "Iteration 33, loss = 0.00085591\n",
      "Iteration 34, loss = 0.00088717\n",
      "Iteration 35, loss = 0.00089636\n",
      "Iteration 36, loss = 0.00080363\n",
      "Iteration 37, loss = 0.00075224\n",
      "Iteration 38, loss = 0.00074791\n",
      "Iteration 39, loss = 0.00069800\n",
      "Iteration 40, loss = 0.00068339\n",
      "Iteration 41, loss = 0.00070018\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.01892181\n",
      "Iteration 2, loss = 0.01064479\n",
      "Iteration 3, loss = 0.00533648\n",
      "Iteration 4, loss = 0.00747142\n",
      "Iteration 5, loss = 0.00700277\n",
      "Iteration 6, loss = 0.00442564\n",
      "Iteration 7, loss = 0.00455250\n",
      "Iteration 8, loss = 0.00353528\n",
      "Iteration 9, loss = 0.00199054\n",
      "Iteration 10, loss = 0.00224662\n",
      "Iteration 11, loss = 0.00284394\n",
      "Iteration 12, loss = 0.00230391\n",
      "Iteration 13, loss = 0.00199579\n",
      "Iteration 14, loss = 0.00241621\n",
      "Iteration 15, loss = 0.00220443\n",
      "Iteration 16, loss = 0.00161280\n",
      "Iteration 17, loss = 0.00164227\n",
      "Iteration 18, loss = 0.00183469\n",
      "Iteration 19, loss = 0.00156264\n",
      "Iteration 20, loss = 0.00137204\n",
      "Iteration 21, loss = 0.00155355\n",
      "Iteration 22, loss = 0.00153716\n",
      "Iteration 23, loss = 0.00124058\n",
      "Iteration 24, loss = 0.00113420\n",
      "Iteration 25, loss = 0.00119289\n",
      "Iteration 26, loss = 0.00107882\n",
      "Iteration 27, loss = 0.00091902\n",
      "Iteration 28, loss = 0.00095331\n",
      "Iteration 29, loss = 0.00100450\n",
      "Iteration 30, loss = 0.00090164\n",
      "Iteration 31, loss = 0.00081867\n",
      "Iteration 32, loss = 0.00084104\n",
      "Iteration 33, loss = 0.00080018\n",
      "Iteration 34, loss = 0.00069743\n",
      "Iteration 35, loss = 0.00069163\n",
      "Iteration 36, loss = 0.00072375\n",
      "Iteration 37, loss = 0.00067597\n",
      "Iteration 38, loss = 0.00063620\n",
      "Iteration 39, loss = 0.00065091\n",
      "Iteration 40, loss = 0.00061869\n",
      "Iteration 41, loss = 0.00057010\n",
      "Iteration 42, loss = 0.00058463\n",
      "Iteration 43, loss = 0.00056660\n",
      "Iteration 44, loss = 0.00053791\n",
      "Iteration 45, loss = 0.00054039\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.01757648\n",
      "Iteration 2, loss = 0.01028540\n",
      "Iteration 3, loss = 0.00495761\n",
      "Iteration 4, loss = 0.00631428\n",
      "Iteration 5, loss = 0.00636958\n",
      "Iteration 6, loss = 0.00374098\n",
      "Iteration 7, loss = 0.00404163\n",
      "Iteration 8, loss = 0.00339408\n",
      "Iteration 9, loss = 0.00172947\n",
      "Iteration 10, loss = 0.00167116\n",
      "Iteration 11, loss = 0.00229915\n",
      "Iteration 12, loss = 0.00185295\n",
      "Iteration 13, loss = 0.00139421\n",
      "Iteration 14, loss = 0.00182424\n",
      "Iteration 15, loss = 0.00185233\n",
      "Iteration 16, loss = 0.00127884\n",
      "Iteration 17, loss = 0.00120812\n",
      "Iteration 18, loss = 0.00144540\n",
      "Iteration 19, loss = 0.00121997\n",
      "Iteration 20, loss = 0.00092099\n",
      "Iteration 21, loss = 0.00106408\n",
      "Iteration 22, loss = 0.00115962\n",
      "Iteration 23, loss = 0.00091853\n",
      "Iteration 24, loss = 0.00080801\n",
      "Iteration 25, loss = 0.00090716\n",
      "Iteration 26, loss = 0.00082323\n",
      "Iteration 27, loss = 0.00063885\n",
      "Iteration 28, loss = 0.00066245\n",
      "Iteration 29, loss = 0.00073516\n",
      "Iteration 30, loss = 0.00064652\n",
      "Iteration 31, loss = 0.00057755\n",
      "Iteration 32, loss = 0.00063162\n",
      "Iteration 33, loss = 0.00061642\n",
      "Iteration 34, loss = 0.00051644\n",
      "Iteration 35, loss = 0.00050627\n",
      "Iteration 36, loss = 0.00054045\n",
      "Iteration 37, loss = 0.00049607\n",
      "Iteration 38, loss = 0.00045765\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes = (50,),  activation = 'relu', solver = 'adam', alpha = 0.001, batch_size = 'auto',\n",
    "    learning_rate = 'constant', learning_rate_init = 0.01, power_t = 0.5, max_iter = 1000, shuffle = True,\n",
    "    random_state = 9, tol = 0.0001, verbose = True, warm_start = False, momentum = 0.9, nesterovs_momentum = True,\n",
    "    early_stopping = False, validation_fraction = 0.1, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08)\n",
    "svr = SVR(kernel = 'linear', C = 0.25, epsilon = 0.01, verbose = True, max_iter = 1000)\n",
    "lr = LinearRegression()\n",
    "\n",
    "full_predict_lr = cross_val_predict(lr, X, target, cv = 10)\n",
    "full_predict_mlp = cross_val_predict(mlp, X, target, cv = 10)\n",
    "full_predict_svr = cross_val_predict(svr, X, target, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error in MLP: 0.0024331421113141806\n",
      "Mean Squared Error in SVR: 0.000614241050622446\n",
      "Mean Squared Error in LR: 1.145106878535077e-31\n",
      "111\n",
      "111\n",
      "111\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error in MLP: %s' %(metrics.mean_squared_error(target, full_predict_mlp)))\n",
    "print('Mean Squared Error in SVR: %s' %(metrics.mean_squared_error(target, full_predict_svr)))\n",
    "print('Mean Squared Error in LR: %s' %(metrics.mean_squared_error(target, full_predict_lr)))\n",
    "\n",
    "print(len(full_predict_mlp))\n",
    "print(len(full_predict_svr))\n",
    "print(len(full_predict_lr))\n",
    "\n",
    "print(len(data['CasosNormalizados']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 1)\n",
      "(117, 1)\n",
      "(117, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "values_to_add = list()\n",
    "for i in range(0, window_size):\n",
    "    values_to_add.append(float('NaN'))\n",
    "    \n",
    "full_predict_svr = np.insert(full_predict_svr, 0, values_to_add)\n",
    "full_predict_svr.shape = (len(full_predict_svr), 1)\n",
    "    \n",
    "full_predict_mlp = np.insert(full_predict_mlp, 0, values_to_add)\n",
    "full_predict_mlp.shape = (len(full_predict_mlp), 1)\n",
    "\n",
    "full_predict_lr = np.insert(full_predict_lr, 0, values_to_add)\n",
    "full_predict_lr.shape = (len(full_predict_lr), 1)\n",
    "\n",
    "print(full_predict_svr.shape)\n",
    "print(full_predict_mlp.shape)\n",
    "print(full_predict_lr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casos</th>\n",
       "      <th>Taxa</th>\n",
       "      <th>CasosNormalizados</th>\n",
       "      <th>TaxaNormalizadas</th>\n",
       "      <th>Predict_lr</th>\n",
       "      <th>Predict_mlp</th>\n",
       "      <th>Predict_svr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26/2/20</th>\n",
       "      <td>1</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27/2/20</th>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28/2/20</th>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/2/20</th>\n",
       "      <td>0</td>\n",
       "      <td>31.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/3/20</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.461333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/6/20</th>\n",
       "      <td>34918</td>\n",
       "      <td>37.3</td>\n",
       "      <td>0.637527</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.637527</td>\n",
       "      <td>0.650432</td>\n",
       "      <td>0.604122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18/6/20</th>\n",
       "      <td>32188</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.587683</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.587683</td>\n",
       "      <td>0.670271</td>\n",
       "      <td>0.600747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19/6/20</th>\n",
       "      <td>22765</td>\n",
       "      <td>34.7</td>\n",
       "      <td>0.415640</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.415640</td>\n",
       "      <td>0.497580</td>\n",
       "      <td>0.459438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20/6/20</th>\n",
       "      <td>54771</td>\n",
       "      <td>39.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687313</td>\n",
       "      <td>0.809068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21/6/20</th>\n",
       "      <td>34666</td>\n",
       "      <td>47.3</td>\n",
       "      <td>0.632926</td>\n",
       "      <td>0.602667</td>\n",
       "      <td>0.632926</td>\n",
       "      <td>0.708238</td>\n",
       "      <td>0.653361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Casos  Taxa  CasosNormalizados  TaxaNormalizadas  Predict_lr  \\\n",
       "Data                                                                    \n",
       "26/2/20      1  24.7           0.000018          0.000000         NaN   \n",
       "27/2/20      0  27.5           0.000000          0.074667         NaN   \n",
       "28/2/20      0  26.6           0.000000          0.050667         NaN   \n",
       "29/2/20      0  31.4           0.000000          0.178667         NaN   \n",
       "1/3/20       1    42           0.000018          0.461333         NaN   \n",
       "...        ...   ...                ...               ...         ...   \n",
       "17/6/20  34918  37.3           0.637527          0.336000    0.637527   \n",
       "18/6/20  32188  38.5           0.587683          0.368000    0.587683   \n",
       "19/6/20  22765  34.7           0.415640          0.266667    0.415640   \n",
       "20/6/20  54771  39.1           1.000000          0.384000    1.000000   \n",
       "21/6/20  34666  47.3           0.632926          0.602667    0.632926   \n",
       "\n",
       "         Predict_mlp  Predict_svr  \n",
       "Data                               \n",
       "26/2/20          NaN          NaN  \n",
       "27/2/20          NaN          NaN  \n",
       "28/2/20          NaN          NaN  \n",
       "29/2/20          NaN          NaN  \n",
       "1/3/20           NaN          NaN  \n",
       "...              ...          ...  \n",
       "17/6/20     0.650432     0.604122  \n",
       "18/6/20     0.670271     0.600747  \n",
       "19/6/20     0.497580     0.459438  \n",
       "20/6/20     0.687313     0.809068  \n",
       "21/6/20     0.708238     0.653361  \n",
       "\n",
       "[117 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Predict_lr'] = full_predict_lr\n",
    "data['Predict_mlp'] = full_predict_mlp\n",
    "data['Predict_svr'] = full_predict_svr\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data.plot(y=['CasosNormalizados', 'Predict_mlp', 'Predict_svr', 'Predict_lr'], style=['-s', '--o'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
